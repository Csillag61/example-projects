{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petfinder.com adoption factor exploration by Paige McKenzie\n",
    "\n",
    "Implements methods discussed in related [blog post](#).\n",
    "\n",
    "Data can be acquired using associated `scraper.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = pd.read_csv('pets_new.csv', index_col=0, parse_dates=['published_at', 'status_changed_at'])\n",
    "\n",
    "for col in ['attributes', 'breeds', 'colors', 'environment']:\n",
    "    pets = pd.concat([pets, pd.DataFrame(pets[col].apply(eval).tolist()).rename(columns=lambda subcol:'{}_{}'.format(col, subcol))],\n",
    "                     axis=1)\n",
    "    del pets[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "# remove anything inside parenthesis\n",
    "# remove anything inside asterisks\n",
    "# remove any word with a digit in it\n",
    "# split on common punctuation and take first word\n",
    "# replace multiple punctuation with single\n",
    "# take first name if \"and/&\" is included\n",
    "# only keep word characters\n",
    "# strip outside punctuation\n",
    "pets['clean_name'] = pets['name'].str.lower().apply(lambda \n",
    "                        name:re.sub(r\"\\(.+\\)\", \" \", name)).apply(lambda \n",
    "                        name:re.sub(r\"\\*.+\\*\", \" \", name)).apply(lambda \n",
    "                        name:re.sub(r\"\\d+\\b\", \" \", name)).apply(lambda \n",
    "                        name:re.split(r\"[-,]\\s+\", name)[0]).apply(lambda\n",
    "                        name:re.split(r\"(\\&|and) \", name)[0]).apply(lambda\n",
    "                        name:re.sub(r\"[^\\w' ]\", \" \", name)).apply(lambda\n",
    "                        name:re.sub(r\"\\s+\", \" \", name)).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only retain clean words in description\n",
    "\n",
    "a = set(re.findall(r\"\\b[a-z']+\\b\", ' '.join(cats['description'].fillna(''))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem words in description\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "{stemmer.stem(word) for word in a}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats['description'].fillna('').str.lower().apply(lambda sentence:re.findall(r\"\\b[^\\d\\s]+\\b\", sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(re.findall(r\"\\b[^\\d\\s,\\/\\-]+\\b\", ' '.join(cats['description'].fillna(''))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word for word in a if pos_tag([word])[0][1].startswith('JJ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_features=500)\n",
    "\n",
    "vect.fit(cats['description'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criteria = pd.Series([tag.startswith('JJ') or tag=='VBN' for word, tag in pos_tag(vect.vocabulary_.keys())],\n",
    "          index=vect.vocabulary_.keys())\n",
    "\n",
    "pd.DataFrame(vect.transform(cats['description'].fillna('')).todense(),\n",
    "             columns=vect.vocabulary_, index=cats.index).loc[:,criteria[criteria].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "cats['description'].head(500).fillna('').apply(lambda sentence:\n",
    "                                 ' '.join([word for word, pos in pos_tag(word_tokenize(sentence.lower())) if pos.startswith('JJ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vect.transform(pets['description']).todense(), index=pets.index,\n",
    "             columns=vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lift(a, b):\n",
    "    total_size = len(a)\n",
    "    num_a = a.sum()\n",
    "    num_b = b.sum()\n",
    "    num_a_b = (a&b).sum()\n",
    "    return total_size*float(num_a_b)/float(num_a*num_b)\n",
    "\n",
    "#pd.Series({name:calc_lift(name, 'XL', pets) for name in pets['clean_name'].unique()}).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = pets[pets['animal']=='Dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = pd.get_dummies(pets['breeds'].apply(pd.Series).stack()).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_lift((pets['mix']=='yes'), (breeds['Pit Bull Terrier']==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets['time_since_update'] = (pets['date_pulled'] - pd.to_datetime(pets['lastUpdate']).dt.date).dt.days / 30\n",
    "\n",
    "pets['time_since_update'].hist(bins=30)\n",
    "plt.title(\"Distribution of time since the listing was updated\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume any pet posted for more than 20 months is an abandoned listing\n",
    "pets = pets[pets['time_since_update']<20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
